{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:09:10.892327Z",
     "start_time": "2018-09-05T00:08:53.024671Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import re\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup twitter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:09:11.005249Z",
     "start_time": "2018-09-05T00:09:10.980643Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative_tweets.json', 'positive_tweets.json', 'tweets.20150430-223406.json']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_samples.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:09:13.294020Z",
     "start_time": "2018-09-05T00:09:11.065489Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "neg_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:09:13.425434Z",
     "start_time": "2018-09-05T00:09:13.399114Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_dataset = pd.DataFrame(pos_tweets,columns=['Tweet'])\n",
    "pos_dataset['Sentiment'] = 1\n",
    "neg_dataset = pd.DataFrame(neg_tweets,columns=['Tweet'])\n",
    "neg_dataset['Sentiment'] = 0\n",
    "\n",
    "dataset = pos_dataset.append(neg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T17:24:57.749845Z",
     "start_time": "2018-09-04T17:24:57.745844Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset = dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup and tokenize the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:09:13.627793Z",
     "start_time": "2018-09-05T00:09:13.581252Z"
    }
   },
   "outputs": [],
   "source": [
    "negation_words = set(['no','not'] + [word for word in stopwords.words('english') if re.search(\"n'\",word)])\n",
    "unwanted_words = set(stopwords.words('english')).difference(negation_words)\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def tokenize(raw_tweet):\n",
    "    tweet = raw_tweet.lower()\n",
    "    tweet = tweet.split()\n",
    "    tweet = [ps.stem(word) for word in tweet if word not in unwanted_words]\n",
    "    tweet = \" \".join(tweet)\n",
    "    tweet = re.sub(\"[^a-zA-Z]\",\" \",tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:44:47.173103Z",
     "start_time": "2018-09-05T00:44:43.371534Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['corpus'] = dataset['Tweet'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:44:50.205035Z",
     "start_time": "2018-09-05T00:44:50.174868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
       "      <td>1</td>\n",
       "      <td>followfriday  france int  pkuchly    milipol ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
       "      <td>1</td>\n",
       "      <td>lamb ja hey james  odd    pleas call contact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
       "      <td>1</td>\n",
       "      <td>despiteoffici listen last night    bleed amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@97sides CONGRATS :)</td>\n",
       "      <td>1</td>\n",
       "      <td>side congrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
       "      <td>1</td>\n",
       "      <td>yeaaaah yippppy    accnt verifi rqst succeed g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment  \\\n",
       "0  #FollowFriday @France_Inte @PKuchly57 @Milipol...          1   \n",
       "1  @Lamb2ja Hey James! How odd :/ Please call our...          1   \n",
       "2  @DespiteOfficial we had a listen last night :)...          1   \n",
       "3                               @97sides CONGRATS :)          1   \n",
       "4  yeaaaah yippppy!!!  my accnt verified rqst has...          1   \n",
       "\n",
       "                                              corpus  \n",
       "0   followfriday  france int  pkuchly    milipol ...  \n",
       "1   lamb ja hey james  odd    pleas call contact ...  \n",
       "2   despiteoffici listen last night    bleed amaz...  \n",
       "3                                    side congrat     \n",
       "4  yeaaaah yippppy    accnt verifi rqst succeed g...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Matrices for ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:46:22.806010Z",
     "start_time": "2018-09-05T00:46:22.395319Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = pd.DataFrame(cv.fit_transform(dataset['corpus']).toarray())\n",
    "y = dataset['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:46:27.225709Z",
     "start_time": "2018-09-05T00:46:27.045046Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.15, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:47:13.156824Z",
     "start_time": "2018-09-05T00:46:43.314685Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = [GaussianNB(),\n",
    "              DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "              ]\n",
    "y_pred = []\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred.append(classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:47:13.888787Z",
     "start_time": "2018-09-05T00:47:13.852154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[629 138]\n",
      " [388 345]] \n",
      "\n",
      "[[598 169]\n",
      " [246 487]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = [confusion_matrix(y_test, y_p) for y_p in y_pred]\n",
    "for matrix in cm:\n",
    "    print(matrix,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:47:14.758053Z",
     "start_time": "2018-09-05T00:47:14.725459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.649333333333\n",
      "0.723333333333\n"
     ]
    }
   ],
   "source": [
    "for array in cm:\n",
    "    print(array.trace()/array.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate incorrect tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:50:06.458499Z",
     "start_time": "2018-09-05T00:50:06.447417Z"
    }
   },
   "outputs": [],
   "source": [
    "incorrect = y_test != y_pred[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:51:30.030786Z",
     "start_time": "2018-09-05T00:51:30.005234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>Hi happys!!:) http://t.co/AGiLlxJdbi</td>\n",
       "      <td>1</td>\n",
       "      <td>hi happys     http   t co agillxjdbi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>Twitter Help Center | Why can&amp;amp;#39;t I foll...</td>\n",
       "      <td>0</td>\n",
       "      <td>twitter help center   can amp     t follow peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>My mister is the best mister :) supportive, ki...</td>\n",
       "      <td>1</td>\n",
       "      <td>mister best mister    supportive  kind  absolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>OH MY GAAAWD :( https://t.co/ZAd3jg0jzF</td>\n",
       "      <td>0</td>\n",
       "      <td>oh gaaawd    https   t co zad jg jzf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>i drew @JustinNFJK :))\\n#WIP #SWS #crush @SWSt...</td>\n",
       "      <td>1</td>\n",
       "      <td>drew  justinnfjk      wip  sw  crush  swstheba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Sentiment  \\\n",
       "906                Hi happys!!:) http://t.co/AGiLlxJdbi          1   \n",
       "906   Twitter Help Center | Why can&amp;#39;t I foll...          0   \n",
       "2343  My mister is the best mister :) supportive, ki...          1   \n",
       "2343            OH MY GAAAWD :( https://t.co/ZAd3jg0jzF          0   \n",
       "2670  i drew @JustinNFJK :))\\n#WIP #SWS #crush @SWSt...          1   \n",
       "\n",
       "                                                 corpus  \n",
       "906                hi happys     http   t co agillxjdbi  \n",
       "906   twitter help center   can amp     t follow peo...  \n",
       "2343  mister best mister    supportive  kind  absolu...  \n",
       "2343               oh gaaawd    https   t co zad jg jzf  \n",
       "2670  drew  justinnfjk      wip  sw  crush  swstheba...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[y_test[incorrect].index,:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement VADER method for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T03:38:23.369490Z",
     "start_time": "2018-09-05T03:38:23.350603Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T02:08:26.725750Z",
     "start_time": "2018-09-05T02:08:26.679664Z"
    }
   },
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T03:40:35.297091Z",
     "start_time": "2018-09-05T03:40:17.974044Z"
    }
   },
   "outputs": [],
   "source": [
    "keys = ['pos','neg','neu','compound']\n",
    "vader = pd.DataFrame(dataset['Tweet'],index=dataset.index)\n",
    "for key in keys:\n",
    "    vader[key] = vader['Tweet'].apply(lambda tweet: sid.polarity_scores(tweet)[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T03:40:36.162818Z",
     "start_time": "2018-09-05T03:40:36.133906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.6229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.7959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@97sides CONGRATS :)</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.7983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.7950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet    pos    neg    neu  \\\n",
       "0  #FollowFriday @France_Inte @PKuchly57 @Milipol...  0.385  0.000  0.615   \n",
       "1  @Lamb2ja Hey James! How odd :/ Please call our...  0.270  0.145  0.585   \n",
       "2  @DespiteOfficial we had a listen last night :)...  0.294  0.000  0.706   \n",
       "3                               @97sides CONGRATS :)  0.877  0.000  0.123   \n",
       "4  yeaaaah yippppy!!!  my accnt verified rqst has...  0.282  0.000  0.718   \n",
       "\n",
       "   compound  \n",
       "0    0.7579  \n",
       "1    0.6229  \n",
       "2    0.7959  \n",
       "3    0.7983  \n",
       "4    0.7950  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T03:40:36.897920Z",
     "start_time": "2018-09-05T03:40:36.871617Z"
    }
   },
   "outputs": [],
   "source": [
    "vader['Sentiment'] = vader['compound'].apply(lambda x: 1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T03:40:37.764170Z",
     "start_time": "2018-09-05T03:40:37.722899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3970 1030]\n",
      " [ 390 4610]] \n",
      "\n",
      "0.858\n"
     ]
    }
   ],
   "source": [
    "vader_cm = confusion_matrix(dataset['Sentiment'],vader['Sentiment'])\n",
    "print(vader_cm, '\\n')\n",
    "\n",
    "print(vader_cm.trace()/vader_cm.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK VADER method is much more successful at predicting tweets than the simple ML models implemented before; 85% accuracy vs 72%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "227px",
    "left": "244px",
    "right": "88px",
    "top": "131px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
