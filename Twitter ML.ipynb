{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T02:34:26.968344Z",
     "start_time": "2018-09-04T02:34:26.383905Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import re\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup twitter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-03T22:08:47.946407Z",
     "start_time": "2018-09-03T22:08:47.917513Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative_tweets.json', 'positive_tweets.json', 'tweets.20150430-223406.json']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_samples.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-03T22:08:53.203780Z",
     "start_time": "2018-09-03T22:08:51.126503Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "neg_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-03T22:15:23.087831Z",
     "start_time": "2018-09-03T22:15:23.057220Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_dataset = pd.DataFrame(pos_tweets,columns=['Tweet'])\n",
    "pos_dataset['Sentiment'] = 1\n",
    "neg_dataset = pd.DataFrame(neg_tweets,columns=['Tweet'])\n",
    "neg_dataset['Sentiment'] = 0\n",
    "\n",
    "dataset = pos_dataset.append(neg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-03T22:17:14.563958Z",
     "start_time": "2018-09-03T22:17:14.543711Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup and tokenize the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T01:30:47.876720Z",
     "start_time": "2018-09-04T01:30:47.852713Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def tokenize(raw_tweet):\n",
    "    tweet = re.sub(\"[^a-zA-Z]\",\" \",raw_tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.split()\n",
    "    tweet = [ps.stem(word) for word in tweet if word not in set(stopwords.words('english'))]\n",
    "    tweet = \" \".join(tweet)\n",
    "    return tweet    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T01:32:18.990507Z",
     "start_time": "2018-09-04T01:30:49.610895Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = dataset['Tweet'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T01:34:04.178932Z",
     "start_time": "2018-09-04T01:34:04.146849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1547                                  hous scari af night\n",
       "2818    nickiepedia parent na plan usual work huhu cou...\n",
       "473                                smileformeacc hug mani\n",
       "3921                   gvmba shoulda let borrow one knive\n",
       "1780    sophielbradshaw realli sorri hear sophi certai...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>My house scary AF at night :(</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818</th>\n",
       "      <td>@nickiepedia :( I can't. My parents are here n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>@Smileformeacc  *hug* you have many :)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>@Gvmba shoulda let me borrow one of those kniv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>@sophielbradshaw We are really sorry to hear t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Sentiment\n",
       "1547                      My house scary AF at night :(          0\n",
       "2818  @nickiepedia :( I can't. My parents are here n...          0\n",
       "473              @Smileformeacc  *hug* you have many :)          1\n",
       "3921  @Gvmba shoulda let me borrow one of those kniv...          1\n",
       "1780  @sophielbradshaw We are really sorry to hear t...          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(corpus.head())\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Matrices for ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T02:32:32.956068Z",
     "start_time": "2018-09-04T02:32:32.568975Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset['Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T02:32:33.372807Z",
     "start_time": "2018-09-04T02:32:33.210991Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.15, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T02:37:52.676567Z",
     "start_time": "2018-09-04T02:37:21.993278Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = [GaussianNB(),\n",
    "              DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "              ]\n",
    "y_pred = []\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred.append(classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T02:37:56.310803Z",
     "start_time": "2018-09-04T02:37:56.287770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[592, 162],\n",
       "        [348, 398]], dtype=int64), array([[558, 196],\n",
       "        [252, 494]], dtype=int64)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = [confusion_matrix(y_test, y_p) for y_p in y_pred]\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T02:38:31.551769Z",
     "start_time": "2018-09-04T02:38:31.530094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66\n",
      "0.701333333333\n"
     ]
    }
   ],
   "source": [
    "for array in cm:\n",
    "    print(array.trace()/array.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "227px",
    "left": "244px",
    "right": "88px",
    "top": "131px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
